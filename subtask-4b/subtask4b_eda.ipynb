{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfnQvGfvtH1w"
   },
   "source": [
    "# CLEF 2025 - CheckThat!\n",
    "## LabTask 4 Scientific Web Discourse - Subtask 4b (Scientific Claim Source Retrieval)\n",
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1736361906940,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8N7h9BhQI5m"
   },
   "source": [
    "## 1.a) Import CORD Dataset\n",
    "The data contains metadata of CORD-19 academic papers.\n",
    "\n",
    "The preprocessed and filtered CORD-19 dataset is available here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4?ref_type=heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736361906941,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "PATH_COLLECTION_DATA = 'subtask4b_collection_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1736361999132,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "SYBB3UYbMwTA"
   },
   "outputs": [],
   "source": [
    "df_cord = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1736362002208,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "4v3lygNOQQSn",
    "outputId": "8312994b-903c-42fb-d717-a8359567f7ae"
   },
   "outputs": [],
   "source": [
    "df_cord.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1736362004263,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "uQU9B3X3gw-_",
    "outputId": "39c3bf2d-6abf-4735-f6a3-e70d3f2176c2"
   },
   "outputs": [],
   "source": [
    "df_cord.head()\n",
    "df_cord.to_csv('cord.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAUiDU0xXLBt"
   },
   "source": [
    "## 1.b) Import the Tweets Dataset\n",
    "The query set contains tweets with implicit references to academic papers from the collection set.\n",
    "\n",
    "The preprocessed query set is available here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4?ref_type=heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1736362007047,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "v8gwkZDSXPsd"
   },
   "outputs": [],
   "source": [
    "PATH_QUERY_DATA = 'subtask4b_query_tweets.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1736362008434,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(PATH_QUERY_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1736362012698,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "szMEK3OkYLvX",
    "outputId": "c283d1b5-813f-43c0-9633-98d10d6aac6e"
   },
   "outputs": [],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1736362014938,
     "user": {
      "displayName": "Salim Hafid",
      "userId": "17094708653963648944"
     },
     "user_tz": -60
    },
    "id": "aslmTTJQyL2X",
    "outputId": "f651b4cc-09eb-41ee-ccaa-befd57e019ad"
   },
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CORD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cord.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) Bar Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources (source_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_x = df_cord['source_x'].to_list()\n",
    "source_x = [string.split(\";\")[0].strip() for string in source_x]\n",
    "unique_source_x = list(set(source_x))\n",
    "\n",
    "plt.hist(x=source_x, bins=len(unique_source_x), width=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Journals (journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = df_cord['journal'].value_counts().nlargest(20)\n",
    "journals.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_cord['authors'].str.split(';', expand=True)\n",
    "author_list = []\n",
    "for column in df1.columns:\n",
    "    df1[column] = df1[column].str.strip()\n",
    "    for item in list(df1[column].values):\n",
    "        author_list.append(item)\n",
    "author_list = [x for x in author_list if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_credits=len(author_list)\n",
    "num_authors = len(set(author_list))\n",
    "\n",
    "print(\"Number of authors: {}\".format(num_authors))\n",
    "print(\"Number of credits: {}\".format(num_credits))\n",
    "print(\"Percent of authors with multiple publications: {0:.2%}\".format(num_authors/num_credits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.DataFrame(author_list)[0].value_counts().nlargest(20)\n",
    "authors.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tweets Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopword_list = [\"\", \"-\", \"&amp;\", \"likely\", \"new\", \"may\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "    filtered_tokens = [token for token in text if token.lower() not in stopword_list]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies(words):\n",
    "    text = words.str.cat(sep=' ')\n",
    "    return Counter(remove_stopwords(text.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_frequencies = word_frequencies(df_tweets['tweet_text'])\n",
    "cord_abstract_frequencies = word_frequencies(df_cord['abstract'])\n",
    "cord_title_frequencies = word_frequencies(df_cord['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(tweet_frequencies)\n",
    "\n",
    "# Display word clouds\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(tweets_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud for Tweets\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "tweets_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(cord_abstract_frequencies)\n",
    "\n",
    "# Display word clouds\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(tweets_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud for CORD Abstracts\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "tweets_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(cord_title_frequencies)\n",
    "\n",
    "# Display word clouds\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(tweets_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud for CORD Titles\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
